(window.webpackJsonp=window.webpackJsonp||[]).push([[5],{171:function(t,s,a){"use strict";a.r(s);var n=a(0),o=Object(n.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"content"},[a("h1",{attrs:{id:"宽度优先搜索算法（bfs）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#宽度优先搜索算法（bfs）","aria-hidden":"true"}},[t._v("#")]),t._v(" 宽度优先搜索算法（BFS）")]),t._v(" "),a("h2",{attrs:{id:"队列"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#队列","aria-hidden":"true"}},[t._v("#")]),t._v(" 队列")]),t._v(" "),a("p",[t._v("在算法中，队列常用于宽度优先搜索(BFS)中，记录待扩展的节点。在工业界，队列可用于实现消息队(message queue)，以完成异步(asynchronous)任务。")]),t._v(" "),a("p",[t._v("“消息”是计算机间传送的数据，可以只包含文本；也可复杂到包含嵌入对象。当消息“生产”和“消费”的速度不一致时，就需要消息队列，临时保存那些已经发送而并未接收的消息。例如集体打包调度，服务器繁忙时的任务处理，事件驱动等等。")]),t._v(" "),a("p",[t._v("常用的消息队列实现包括 RabbitMQ，ZeroMQ 等等。")]),t._v(" "),a("h2",{attrs:{id:"interface"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#interface","aria-hidden":"true"}},[t._v("#")]),t._v(" Interface")]),t._v(" "),a("h3",{attrs:{id:"set"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set","aria-hidden":"true"}},[t._v("#")]),t._v(" Set")]),t._v(" "),a("p",[t._v("HashSet: 无重复数据，"),a("strong",[t._v("可以")]),t._v("有空数据，数据"),a("strong",[t._v("无序")]),t._v("。\nTreeSet: 无重复数据，"),a("strong",[t._v("不能")]),t._v("有空数据，数据"),a("strong",[t._v("有序")]),t._v("。")]),t._v(" "),a("h3",{attrs:{id:"map"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#map","aria-hidden":"true"}},[t._v("#")]),t._v(" Map")]),t._v(" "),a("p",[t._v("HashMap: key 无重复，value 允许重复；允许 key 和 value 为空；数据无序。\nTreeMap: key 无重复，value 允许重复；不允许有 null；数据有序。")]),t._v(" "),a("h3",{attrs:{id:"list"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#list","aria-hidden":"true"}},[t._v("#")]),t._v(" List")]),t._v(" "),a("p",[t._v("ArrayList 与 LinkedList 的区别：")]),t._v(" "),a("ul",[a("li",[t._v("ArrayList 基于动态数组实现，LinkedList 基于链表实现。")]),t._v(" "),a("li",[t._v("对于随机访问 get 和 set，ArrayList 绝对优于 LinkedList，因为 LinkedList 要移动指针。")]),t._v(" "),a("li",[t._v("对于新增和删除操作 add 和 remove，LinedList 比较占优势，因为 ArrayList 要移动数据。")])]),t._v(" "),a("h3",{attrs:{id:"queue"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#queue","aria-hidden":"true"}},[t._v("#")]),t._v(" Queue")]),t._v(" "),a("p",[t._v("PriorityQueue 和 LinkedList 的区别：")]),t._v(" "),a("ul",[a("li",[t._v("PriorityQueue 基于堆实现，LinkedList 基于链表实现。")]),t._v(" "),a("li",[t._v("PriorityQueue 非 FIFO，它是优先级最高的元素先出队列；LinkedList 遵循 FIFO。")])]),t._v(" "),a("h2",{attrs:{id:"什么时候用宽度优先算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#什么时候用宽度优先算法","aria-hidden":"true"}},[t._v("#")]),t._v(" 什么时候用宽度优先算法")]),t._v(" "),a("p",[t._v("有如下几种情况可以考虑使用宽度优先算法：")]),t._v(" "),a("ul",[a("li",[t._v("图的遍历(Traversal in Graph)，展开来讲下面几种情况也属于这个类型。\n"),a("ul",[a("li",[t._v("层级遍历(Level Order Traversal)")]),t._v(" "),a("li",[t._v("由点及面(Connected Component)")]),t._v(" "),a("li",[t._v("拓扑排序(Topological Sorting)")])])]),t._v(" "),a("li",[t._v("最短路径(Shortest Path in Simple Graph)")])]),t._v(" "),a("h3",{attrs:{id:"二叉树的-bfs-vs-图的-bfs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二叉树的-bfs-vs-图的-bfs","aria-hidden":"true"}},[t._v("#")]),t._v(" 二叉树的 BFS VS 图的 BFS")]),t._v(" "),a("p",[t._v("二叉树的 BFS 与图的 BFS 最大的不同是在二叉树中不用使用 HashSet 来存储访问过的节点，因为二叉树中没有环，不像图中会出现一个节点的邻居的邻居会是自己的情况。")]),t._v(" "),a("h2",{attrs:{id:"拓扑排序"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#拓扑排序","aria-hidden":"true"}},[t._v("#")]),t._v(" 拓扑排序")]),t._v(" "),a("p",[t._v("在图论中，由一个有向无环图的顶点组成的序列，当且仅当满足以下条件时，称为该图的一个拓扑排序。")]),t._v(" "),a("ul",[a("li",[t._v("每个顶点出现且只出现一次。")]),t._v(" "),a("li",[t._v("若 A 在序列中排在 B 前面，则在图中不存在 B 到 A 的路径。")])]),t._v(" "),a("p",[t._v("拓扑排序可应用于检测编译时的循环依赖，制定有依赖关系的任务的执行顺序等问题上。另外，拓扑排序不是一种排序算法，一张图的拓扑序列可以有很多个，也可以没有，我们只需找出其中一个序列，而无需找到所有序列。")]),t._v(" "),a("h3",{attrs:{id:"算法描述"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#算法描述","aria-hidden":"true"}},[t._v("#")]),t._v(" 算法描述")]),t._v(" "),a("p",[t._v("介绍算法之前，首先了解图中的基本概念入度和出度。")]),t._v(" "),a("p",[t._v("入度和出度：在有向图中，如果存在一条有向边 A--\x3eB，那么我们认为这条边为 A 增加了一个出度，为 B 增加了一个入度。")]),t._v(" "),a("p",[t._v("拓扑排序的算法是典型的宽度优先搜索算法，其大致流程如下：")]),t._v(" "),a("ul",[a("li",[t._v("统计所有点的入度，并初始化拓扑序列为空。")]),t._v(" "),a("li",[t._v("将所有入度为 0 的点，也就是那些没有任何依赖的点，放到宽度优先搜索的队列中。")]),t._v(" "),a("li",[t._v("将队列中的点一个一个的释放出来，放到拓扑序列中，每次释放出某个点 A 的时候，就访问 A 的相邻点（所有 A 指向的点），并把这些点的入度减去 1。")]),t._v(" "),a("li",[t._v("如果发现某个点的入度被减去 1 之后变成了 0，则放入队列中。")]),t._v(" "),a("li",[t._v("直到队列为空时，算法结束。")])]),t._v(" "),a("p",[t._v("相关题目：https://www.lintcode.com/problem/course-schedule/description")]),t._v(" "),a("h2",{attrs:{id:"宽度优先搜索模版"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#宽度优先搜索模版","aria-hidden":"true"}},[t._v("#")]),t._v(" 宽度优先搜索模版")]),t._v(" "),a("h3",{attrs:{id:"不需分层遍历的宽度优先搜索"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#不需分层遍历的宽度优先搜索","aria-hidden":"true"}},[t._v("#")]),t._v(" 不需分层遍历的宽度优先搜索")]),t._v(" "),a("p",[t._v("宽搜的实现有很多种，下面是利用 queue 和 set 的一种实现。也是最佳实践。")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v("// T 指代任何你希望存储的类型")]),t._v("\nQueue"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("T"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" queue "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("LinkedList")]),a("span",{attrs:{class:"token operator"}},[t._v("<")]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nSet"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("T"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" set "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("HashSet")]),a("span",{attrs:{class:"token operator"}},[t._v("<")]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nset"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("add")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nqueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("offer")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("queue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("isEmpty")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  T head "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" queue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("poll")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("T neighbor "),a("span",{attrs:{class:"token operator"}},[t._v(":")]),t._v(" head"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbors"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("set"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("contains")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      set"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("add")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      queue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("offer")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("注释：")]),t._v(" "),a("ul",[a("li",[t._v("neighbor 表示从某个点 head 出发，可以走到的下一层的节点。")]),t._v(" "),a("li",[t._v("set 存储已经访问过的节点（已经丢到 queue 里去过的节点）。")]),t._v(" "),a("li",[t._v("queue 存储等待被拓展到下一层的节点。")]),t._v(" "),a("li",[t._v("set 与 queue 是一对好基友，无时无刻都一起出现，往 queue 里新增一个节点，就要同时丢到 set 里。")])]),t._v(" "),a("h3",{attrs:{id:"需要分层遍历的宽度优先搜索"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#需要分层遍历的宽度优先搜索","aria-hidden":"true"}},[t._v("#")]),t._v(" 需要分层遍历的宽度优先搜索")]),t._v(" "),a("p",[t._v("如果需要分层，那么要在上面这个算法中稍做修改：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v("// T 指代任何你希望存储的类型")]),t._v("\nQueue"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("T"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" queue "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("LinkedList")]),a("span",{attrs:{class:"token operator"}},[t._v("<")]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nSet"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("T"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" set "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("HashSet")]),a("span",{attrs:{class:"token operator"}},[t._v("<")]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nset"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("add")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nqueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("offer")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("queue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("isEmpty")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{attrs:{class:"token keyword"}},[t._v("int")]),t._v(" size "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" queue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("size")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token keyword"}},[t._v("int")]),t._v(" i "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),a("span",{attrs:{class:"token operator"}},[t._v("<")]),t._v(" size"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),a("span",{attrs:{class:"token operator"}},[t._v("++")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    T head "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" queue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("poll")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("T neighbor "),a("span",{attrs:{class:"token operator"}},[t._v(":")]),t._v(" head"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbors"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("set"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("contains")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        set"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("add")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        queue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("offer")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("h3",{attrs:{id:"使用两个队列实现-bfs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#使用两个队列实现-bfs","aria-hidden":"true"}},[t._v("#")]),t._v(" 使用两个队列实现 BFS")]),t._v(" "),a("h3",{attrs:{id:"使用-dummy-node-实现-bfs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#使用-dummy-node-实现-bfs","aria-hidden":"true"}},[t._v("#")]),t._v(" 使用 dummy node 实现 BFS")]),t._v(" "),a("h2",{attrs:{id:"如何构建图"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何构建图","aria-hidden":"true"}},[t._v("#")]),t._v(" 如何构建图")]),t._v(" "),a("p",[t._v("第一种方法是使用自定义邻接表：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("DirectedGraphNode")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{attrs:{class:"token keyword"}},[t._v("int")]),t._v(" label"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  List"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("DirectedGraphNode"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" neighbors"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("第二种是使用 Map 与 Set 的搭配：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[t._v("HashMap"),a("span",{attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Set"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("T"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),t._v(" graph "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{attrs:{class:"token operator"}},[t._v("<")]),t._v("Integer"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" HashSet"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("Integer"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("// 其中 T 代表节点类型，通常是整数")]),t._v("\n")])])]),a("h2",{attrs:{id:"双向宽度优先搜索算法（bidirectional-bfs）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#双向宽度优先搜索算法（bidirectional-bfs）","aria-hidden":"true"}},[t._v("#")]),t._v(" 双向宽度优先搜索算法（Bidirectional BFS）")]),t._v(" "),a("p",[t._v("双向宽度优先搜索算法适用于如下场景：")]),t._v(" "),a("ul",[a("li",[t._v("无向图")]),t._v(" "),a("li",[t._v("所有边的长度都为 1 或者长度都一样")]),t._v(" "),a("li",[t._v("同时给出了起点和终点")])]),t._v(" "),a("h3",{attrs:{id:"算法描述-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#算法描述-2","aria-hidden":"true"}},[t._v("#")]),t._v(" 算法描述")]),t._v(" "),a("p",[t._v("双向宽度优先搜索本质上还是BFS，只不过变成了起点向终点和终点向起点同时进行扩展，直至两个方向上出现同一个子节点，搜索结束。我们还是可以利用队列来实现：一个队列保存从起点开始搜索的状态，另一个保存从终点开始的状态，两边如果相交了，那么搜索结束。起点到终点的最短距离即为起点到相交节点的距离与终点到相交节点的距离之和。")]),t._v(" "),a("p",[t._v("所以双向宽度优先搜索在某些情况下可以作为宽搜的优化。")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v("/**\n * Definition for graph node.\n * class UndirectedGraphNode {\n *   int label;\n *   ArrayList<UndirectedGraphNode> neighbors;\n *   UndirectedGraphNode(int x) {\n *     label = x; neighbors = new ArrayList<UndirectedGraphNode>();\n *   }\n * };\n */")]),t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("doubleBFS")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("UndirectedGraphNode start"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" UndirectedGraphNode end"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("equals")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  Queue"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("UndirectedGraphNode"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" startQueue "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("LinkedList")]),a("span",{attrs:{class:"token operator"}},[t._v("<")]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  Queue"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("UndirectedGraphNode"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" endQueue "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("LinkedList")]),a("span",{attrs:{class:"token operator"}},[t._v("<")]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  startQueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("offer")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  endQueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("offer")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("end"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  Set"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("UndirectedGraphNode"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" startSet "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("HashSet")]),a("span",{attrs:{class:"token operator"}},[t._v("<")]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  Set"),a("span",{attrs:{class:"token generics function"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("UndirectedGraphNode"),a("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" endSet "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("HashSet")]),a("span",{attrs:{class:"token operator"}},[t._v("<")]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  startSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("add")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  endSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("add")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("end"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),a("span",{attrs:{class:"token keyword"}},[t._v("int")]),t._v(" step "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),a("span",{attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("startQueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("isEmpty")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("endQueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("isEmpty")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("int")]),t._v(" startSize "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" startQueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("size")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("int")]),t._v(" endSize "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" endQueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("size")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    step"),a("span",{attrs:{class:"token operator"}},[t._v("++")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token keyword"}},[t._v("int")]),t._v(" i "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),a("span",{attrs:{class:"token operator"}},[t._v("<")]),t._v(" startSize"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),a("span",{attrs:{class:"token operator"}},[t._v("++")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      UndirectedGraphNode node "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" startQueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("poll")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("UndirectedGraphNode neighbor "),a("span",{attrs:{class:"token operator"}},[t._v(":")]),t._v(" node"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbors"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("startSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("contains")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("// 重复节点")]),t._v("\n          "),a("span",{attrs:{class:"token keyword"}},[t._v("continue")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("endSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("contains")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("// 相交")]),t._v("\n          "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" step"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          startQueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("offer")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n          startSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("add")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    setp"),a("span",{attrs:{class:"token operator"}},[t._v("++")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token keyword"}},[t._v("int")]),t._v(" i "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),a("span",{attrs:{class:"token operator"}},[t._v("<")]),t._v(" endSize"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),a("span",{attrs:{class:"token operator"}},[t._v("++")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      UndirectedGraphNode node "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" endQueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("poll")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("UndirectedGraphNode neighbor "),a("span",{attrs:{class:"token operator"}},[t._v(":")]),t._v(" node"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbors"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("endSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("contains")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("// 重复节点")]),t._v("\n          "),a("span",{attrs:{class:"token keyword"}},[t._v("continue")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("startSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("contains")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("// 相交")]),t._v("\n          "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" step"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          endQueue"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("offer")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n          endSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("add")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("-")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])}],!1,null,null,null);o.options.__file="bfs.md";s.default=o.exports}}]);